{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7045013,"sourceType":"datasetVersion","datasetId":4053823}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing Modules**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer #type:ignore\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences #type: ignore \nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau #type: ignore\nfrom tensorflow.keras.utils import Sequence #type: ignore\nimport tensorflow.keras.utils as ku \nimport pandas as pd \nimport numpy as np\nimport string\nimport pickle\nimport gc  ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:10:58.023425Z","iopub.execute_input":"2025-08-11T23:10:58.023783Z","iopub.status.idle":"2025-08-11T23:10:58.028964Z","shell.execute_reply.started":"2025-08-11T23:10:58.023761Z","shell.execute_reply":"2025-08-11T23:10:58.028005Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"**Loading the Training data**","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/tinystories-narrative-classification/train.csv\")\n\nDATASET_SIZE = 4000  \ntrain_text = [t for t in train_data[\"text\"][:DATASET_SIZE]]\n\n\n# Deleting the unnecessary stuff to free up ram\ndel train_data\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:10:58.029947Z","iopub.execute_input":"2025-08-11T23:10:58.030168Z","iopub.status.idle":"2025-08-11T23:11:17.687683Z","shell.execute_reply.started":"2025-08-11T23:10:58.030129Z","shell.execute_reply":"2025-08-11T23:11:17.686970Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"5937"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"**Creating preprocessing function**\n","metadata":{}},{"cell_type":"code","source":"def clean_data(text):\n    text = str(text).lower()\n    text = ''.join([i for i in text if i not in string.punctuation]) \n    text = text.encode('utf8').decode('ascii','ignore')\n    return text ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:17.688925Z","iopub.execute_input":"2025-08-11T23:11:17.689195Z","iopub.status.idle":"2025-08-11T23:11:17.693415Z","shell.execute_reply.started":"2025-08-11T23:11:17.689172Z","shell.execute_reply":"2025-08-11T23:11:17.692664Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"**Applying preprocessing**","metadata":{}},{"cell_type":"code","source":"train_text = [clean_data(text) for text in train_text]\nprint(f\"Number of texts: {len(train_text)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:17.694268Z","iopub.execute_input":"2025-08-11T23:11:17.694580Z","iopub.status.idle":"2025-08-11T23:11:17.901825Z","shell.execute_reply.started":"2025-08-11T23:11:17.694555Z","shell.execute_reply":"2025-08-11T23:11:17.901039Z"}},"outputs":[{"name":"stdout","text":"Number of texts: 4000\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"**Setup tokenizer and parameters**","metadata":{}},{"cell_type":"code","source":"MAX_VOCAB_SIZE = 8000\nMAX_SEQUENCE_LENGTH = 60  \n\ntokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(train_text)\n\ntotal_words = min(len(tokenizer.word_index) + 1, MAX_VOCAB_SIZE)\nprint(f\"Vocabulary size: {total_words}\")\n\nsequence_lengths = []\nfor text in train_text[:500]:  \n    token_list = tokenizer.texts_to_sequences([text])[0]\n    sequence_lengths.append(len(token_list))\n\nmax_sequence_len = min(int(np.percentile(sequence_lengths, 95)), MAX_SEQUENCE_LENGTH)\nprint(f\"Max sequence length: {max_sequence_len}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:17.903502Z","iopub.execute_input":"2025-08-11T23:11:17.903721Z","iopub.status.idle":"2025-08-11T23:11:18.230021Z","shell.execute_reply.started":"2025-08-11T23:11:17.903704Z","shell.execute_reply":"2025-08-11T23:11:18.229293Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 7380\nMax sequence length: 60\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**Data Generator**","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, texts, tokenizer, max_sequence_len, batch_size=32):\n        self.texts = texts\n        self.tokenizer = tokenizer\n        self.max_sequence_len = max_sequence_len\n        self.batch_size = batch_size\n        \n        self.sequence_indices = []\n        for text_idx, text in enumerate(texts):\n            token_list = tokenizer.texts_to_sequences([text])[0]\n            max_sequences_per_text = min(len(token_list) - 1, 50)\n            for i in range(1, max_sequences_per_text + 1):\n                self.sequence_indices.append((text_idx, i))\n        \n        print(f\"Total sequences: {len(self.sequence_indices)}\")\n        \n    def __len__(self):\n        return int(np.ceil(len(self.sequence_indices) / self.batch_size))\n    \n    def __getitem__(self, idx):\n        batch_indices = self.sequence_indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n        \n        X, y = [], []\n        for text_idx, seq_end in batch_indices:\n            token_list = self.tokenizer.texts_to_sequences([self.texts[text_idx]])[0]\n            if seq_end < len(token_list):\n                sequence = token_list[:seq_end + 1]\n                X.append(sequence[:-1])\n                y.append(sequence[-1])\n        \n        if len(X) == 0:\n            X = np.zeros((1, self.max_sequence_len - 1))\n            y = np.zeros((1, len(self.tokenizer.word_index) + 1))\n            return X, y\n            \n        X = pad_sequences(X, maxlen=self.max_sequence_len - 1, padding='pre')\n        y = ku.to_categorical(y, num_classes=len(self.tokenizer.word_index) + 1)\n        \n        return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:18.230847Z","iopub.execute_input":"2025-08-11T23:11:18.231122Z","iopub.status.idle":"2025-08-11T23:11:18.239753Z","shell.execute_reply.started":"2025-08-11T23:11:18.231103Z","shell.execute_reply":"2025-08-11T23:11:18.239177Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":" **Create data generator**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE =64\ntrain_generator = DataGenerator(train_text, tokenizer, max_sequence_len, BATCH_SIZE)\n\nprint(f\"Number of batches per epoch: {len(train_generator)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:18.240441Z","iopub.execute_input":"2025-08-11T23:11:18.240783Z","iopub.status.idle":"2025-08-11T23:11:18.489929Z","shell.execute_reply.started":"2025-08-11T23:11:18.240753Z","shell.execute_reply":"2025-08-11T23:11:18.489323Z"}},"outputs":[{"name":"stdout","text":"Total sequences: 199997\nNumber of batches per epoch: 3125\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**Building the model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential #type: ignore\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization\n\ninput_len=max_sequence_len-1\n    \nmodel=Sequential()\n    \n# Embedding layer\nmodel.add(Embedding(total_words,32,input_length=input_len))\nmodel.add(Dropout(0.1))\n\n# 1st LSTM Layer\nmodel.add(LSTM(256,return_sequences=True))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\n# 2nd LSTM Layer\n\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\n# Dense Layer \nmodel.add(Dense(256, activation='relu'))\n# model.add(Dropout(0.4))\n    \n# Output Layer \nmodel.add(Dense(total_words,activation='softmax')) \n    \nmodel.build(input_shape=(None, input_len))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])    \nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:18.490608Z","iopub.execute_input":"2025-08-11T23:11:18.490821Z","iopub.status.idle":"2025-08-11T23:11:18.618741Z","shell.execute_reply.started":"2025-08-11T23:11:18.490804Z","shell.execute_reply":"2025-08-11T23:11:18.618110Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │       \u001b[38;5;34m236,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m295,936\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m197,120\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7380\u001b[0m)           │     \u001b[38;5;34m1,896,660\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">236,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,936</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7380</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,896,660</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,660,436\u001b[0m (10.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,660,436</span> (10.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,659,668\u001b[0m (10.15 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,659,668</span> (10.15 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"**Setting up callbacks**","metadata":{}},{"cell_type":"code","source":"# Early Stopping\nearly_stopping = EarlyStopping(\n    monitor=\"loss\",  \n    restore_best_weights=True,\n    patience=5,\n    min_delta=0.001\n)\n\n# Model Checkpoint\ncheckpoint = ModelCheckpoint(\n    'best_story_model.keras',\n    save_best_only=True,\n    monitor='loss',\n    mode='min',\n    verbose=1\n)\n\n# Reduce Learning Rate\nreduce_lr = ReduceLROnPlateau(\n    monitor=\"loss\",\n    factor=0.5,\n    patience=3,\n    min_lr=1e-6,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:11:18.619502Z","iopub.execute_input":"2025-08-11T23:11:18.619964Z","iopub.status.idle":"2025-08-11T23:11:18.624247Z","shell.execute_reply.started":"2025-08-11T23:11:18.619937Z","shell.execute_reply":"2025-08-11T23:11:18.623647Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"hist=model.fit(train_generator,epochs=150,callbacks=[early_stopping,checkpoint,reduce_lr],batch_size=BATCH_SIZE,verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T23:15:37.250062Z","iopub.execute_input":"2025-08-11T23:15:37.250368Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2950 - loss: 3.9463\nEpoch 1: loss improved from inf to 3.88999, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.2950 - loss: 3.9462 - learning_rate: 0.0010\nEpoch 2/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3172 - loss: 3.6729\nEpoch 2: loss improved from 3.88999 to 3.65106, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3172 - loss: 3.6729 - learning_rate: 0.0010\nEpoch 3/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3308 - loss: 3.5236\nEpoch 3: loss improved from 3.65106 to 3.50485, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3308 - loss: 3.5235 - learning_rate: 0.0010\nEpoch 4/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3434 - loss: 3.3836\nEpoch 4: loss improved from 3.50485 to 3.39580, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.3434 - loss: 3.3836 - learning_rate: 0.0010\nEpoch 5/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3487 - loss: 3.3172\nEpoch 5: loss improved from 3.39580 to 3.31346, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3487 - loss: 3.3172 - learning_rate: 0.0010\nEpoch 6/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3533 - loss: 3.2420\nEpoch 6: loss improved from 3.31346 to 3.24848, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3533 - loss: 3.2420 - learning_rate: 0.0010\nEpoch 7/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3590 - loss: 3.1858\nEpoch 7: loss improved from 3.24848 to 3.19574, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3590 - loss: 3.1858 - learning_rate: 0.0010\nEpoch 8/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3655 - loss: 3.1227\nEpoch 8: loss improved from 3.19574 to 3.14661, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.3655 - loss: 3.1228 - learning_rate: 0.0010\nEpoch 9/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3681 - loss: 3.0883\nEpoch 9: loss improved from 3.14661 to 3.10819, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3681 - loss: 3.0883 - learning_rate: 0.0010\nEpoch 10/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3700 - loss: 3.0703\nEpoch 10: loss improved from 3.10819 to 3.07295, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3700 - loss: 3.0703 - learning_rate: 0.0010\nEpoch 11/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3777 - loss: 3.0141\nEpoch 11: loss improved from 3.07295 to 3.04504, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3777 - loss: 3.0141 - learning_rate: 0.0010\nEpoch 12/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3786 - loss: 2.9833\nEpoch 12: loss improved from 3.04504 to 3.01539, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3786 - loss: 2.9833 - learning_rate: 0.0010\nEpoch 13/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3830 - loss: 2.9604\nEpoch 13: loss improved from 3.01539 to 2.99065, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3830 - loss: 2.9604 - learning_rate: 0.0010\nEpoch 14/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3863 - loss: 2.9319\nEpoch 14: loss improved from 2.99065 to 2.96678, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 16ms/step - accuracy: 0.3863 - loss: 2.9319 - learning_rate: 0.0010\nEpoch 15/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3865 - loss: 2.9269\nEpoch 15: loss improved from 2.96678 to 2.94443, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3865 - loss: 2.9269 - learning_rate: 0.0010\nEpoch 16/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3880 - loss: 2.9074\nEpoch 16: loss improved from 2.94443 to 2.92924, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3880 - loss: 2.9074 - learning_rate: 0.0010\nEpoch 17/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3904 - loss: 2.8811\nEpoch 17: loss improved from 2.92924 to 2.90748, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3904 - loss: 2.8811 - learning_rate: 0.0010\nEpoch 18/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3895 - loss: 2.8802\nEpoch 18: loss improved from 2.90748 to 2.88773, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3895 - loss: 2.8802 - learning_rate: 0.0010\nEpoch 19/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3954 - loss: 2.8438\nEpoch 19: loss improved from 2.88773 to 2.87703, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3954 - loss: 2.8438 - learning_rate: 0.0010\nEpoch 20/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3941 - loss: 2.8384\nEpoch 20: loss improved from 2.87703 to 2.85580, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3941 - loss: 2.8384 - learning_rate: 0.0010\nEpoch 21/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3951 - loss: 2.8218\nEpoch 21: loss improved from 2.85580 to 2.84208, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3951 - loss: 2.8218 - learning_rate: 0.0010\nEpoch 22/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3976 - loss: 2.8194\nEpoch 22: loss improved from 2.84208 to 2.83087, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.3976 - loss: 2.8194 - learning_rate: 0.0010\nEpoch 23/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4004 - loss: 2.7962\nEpoch 23: loss improved from 2.83087 to 2.81637, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4004 - loss: 2.7962 - learning_rate: 0.0010\nEpoch 24/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4040 - loss: 2.7675\nEpoch 24: loss improved from 2.81637 to 2.80317, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4040 - loss: 2.7675 - learning_rate: 0.0010\nEpoch 25/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4016 - loss: 2.7787\nEpoch 25: loss improved from 2.80317 to 2.79571, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4016 - loss: 2.7788 - learning_rate: 0.0010\nEpoch 26/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4035 - loss: 2.7649\nEpoch 26: loss improved from 2.79571 to 2.78109, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4035 - loss: 2.7649 - learning_rate: 0.0010\nEpoch 27/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4019 - loss: 2.7680\nEpoch 27: loss improved from 2.78109 to 2.77410, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4019 - loss: 2.7680 - learning_rate: 0.0010\nEpoch 28/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4055 - loss: 2.7426\nEpoch 28: loss improved from 2.77410 to 2.76283, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4055 - loss: 2.7426 - learning_rate: 0.0010\nEpoch 29/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4052 - loss: 2.7406\nEpoch 29: loss improved from 2.76283 to 2.74922, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4052 - loss: 2.7406 - learning_rate: 0.0010\nEpoch 30/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4052 - loss: 2.7390\nEpoch 30: loss improved from 2.74922 to 2.74574, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4052 - loss: 2.7390 - learning_rate: 0.0010\nEpoch 31/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4062 - loss: 2.7409\nEpoch 31: loss improved from 2.74574 to 2.73605, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4062 - loss: 2.7409 - learning_rate: 0.0010\nEpoch 32/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4067 - loss: 2.7126\nEpoch 32: loss improved from 2.73605 to 2.72441, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4067 - loss: 2.7126 - learning_rate: 0.0010\nEpoch 33/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4094 - loss: 2.7069\nEpoch 33: loss improved from 2.72441 to 2.71244, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4094 - loss: 2.7069 - learning_rate: 0.0010\nEpoch 34/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4120 - loss: 2.6961\nEpoch 34: loss improved from 2.71244 to 2.70916, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4120 - loss: 2.6961 - learning_rate: 0.0010\nEpoch 35/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4111 - loss: 2.6926\nEpoch 35: loss improved from 2.70916 to 2.70060, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4111 - loss: 2.6926 - learning_rate: 0.0010\nEpoch 36/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4168 - loss: 2.6661\nEpoch 36: loss improved from 2.70060 to 2.69218, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4168 - loss: 2.6662 - learning_rate: 0.0010\nEpoch 37/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4167 - loss: 2.6614\nEpoch 37: loss improved from 2.69218 to 2.68483, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4167 - loss: 2.6615 - learning_rate: 0.0010\nEpoch 38/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4163 - loss: 2.6667\nEpoch 38: loss improved from 2.68483 to 2.68004, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4163 - loss: 2.6667 - learning_rate: 0.0010\nEpoch 39/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4163 - loss: 2.6536\nEpoch 39: loss improved from 2.68004 to 2.67112, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4163 - loss: 2.6536 - learning_rate: 0.0010\nEpoch 40/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4176 - loss: 2.6478\nEpoch 40: loss improved from 2.67112 to 2.66563, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4176 - loss: 2.6478 - learning_rate: 0.0010\nEpoch 41/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4179 - loss: 2.6407\nEpoch 41: loss improved from 2.66563 to 2.65997, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4179 - loss: 2.6407 - learning_rate: 0.0010\nEpoch 42/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4186 - loss: 2.6417\nEpoch 42: loss improved from 2.65997 to 2.65309, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4186 - loss: 2.6417 - learning_rate: 0.0010\nEpoch 43/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4215 - loss: 2.6243\nEpoch 43: loss improved from 2.65309 to 2.64648, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4215 - loss: 2.6244 - learning_rate: 0.0010\nEpoch 44/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4207 - loss: 2.6205\nEpoch 44: loss improved from 2.64648 to 2.63938, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4207 - loss: 2.6205 - learning_rate: 0.0010\nEpoch 45/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4210 - loss: 2.6242\nEpoch 45: loss improved from 2.63938 to 2.63648, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4210 - loss: 2.6242 - learning_rate: 0.0010\nEpoch 46/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4226 - loss: 2.6158\nEpoch 46: loss improved from 2.63648 to 2.63083, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4226 - loss: 2.6158 - learning_rate: 0.0010\nEpoch 47/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4231 - loss: 2.6059\nEpoch 47: loss improved from 2.63083 to 2.62287, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4231 - loss: 2.6059 - learning_rate: 0.0010\nEpoch 48/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4212 - loss: 2.6146\nEpoch 48: loss did not improve from 2.62287\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4212 - loss: 2.6146 - learning_rate: 0.0010\nEpoch 49/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4245 - loss: 2.5996\nEpoch 49: loss improved from 2.62287 to 2.61353, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4245 - loss: 2.5996 - learning_rate: 0.0010\nEpoch 50/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4244 - loss: 2.5918\nEpoch 50: loss improved from 2.61353 to 2.61066, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4244 - loss: 2.5918 - learning_rate: 0.0010\nEpoch 51/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4270 - loss: 2.5752\nEpoch 51: loss improved from 2.61066 to 2.60453, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4270 - loss: 2.5752 - learning_rate: 0.0010\nEpoch 52/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4253 - loss: 2.5829\nEpoch 52: loss improved from 2.60453 to 2.60192, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4253 - loss: 2.5829 - learning_rate: 0.0010\nEpoch 53/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4291 - loss: 2.5644\nEpoch 53: loss improved from 2.60192 to 2.59581, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4291 - loss: 2.5645 - learning_rate: 0.0010\nEpoch 54/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4242 - loss: 2.5790\nEpoch 54: loss improved from 2.59581 to 2.58874, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4242 - loss: 2.5790 - learning_rate: 0.0010\nEpoch 55/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4309 - loss: 2.5591\nEpoch 55: loss did not improve from 2.58874\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4309 - loss: 2.5592 - learning_rate: 0.0010\nEpoch 56/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4270 - loss: 2.5668\nEpoch 56: loss improved from 2.58874 to 2.58092, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4270 - loss: 2.5668 - learning_rate: 0.0010\nEpoch 57/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4263 - loss: 2.5728\nEpoch 57: loss improved from 2.58092 to 2.57887, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4263 - loss: 2.5728 - learning_rate: 0.0010\nEpoch 58/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4272 - loss: 2.5671\nEpoch 58: loss improved from 2.57887 to 2.57685, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4272 - loss: 2.5671 - learning_rate: 0.0010\nEpoch 59/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4269 - loss: 2.5668\nEpoch 59: loss improved from 2.57685 to 2.57286, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4269 - loss: 2.5668 - learning_rate: 0.0010\nEpoch 60/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4286 - loss: 2.5576\nEpoch 60: loss improved from 2.57286 to 2.56888, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4286 - loss: 2.5576 - learning_rate: 0.0010\nEpoch 61/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4304 - loss: 2.5534\nEpoch 61: loss improved from 2.56888 to 2.56500, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4304 - loss: 2.5534 - learning_rate: 0.0010\nEpoch 62/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4313 - loss: 2.5433\nEpoch 62: loss improved from 2.56500 to 2.56037, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4313 - loss: 2.5433 - learning_rate: 0.0010\nEpoch 63/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4307 - loss: 2.5369\nEpoch 63: loss improved from 2.56037 to 2.55544, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4307 - loss: 2.5369 - learning_rate: 0.0010\nEpoch 64/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4331 - loss: 2.5232\nEpoch 64: loss improved from 2.55544 to 2.55428, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4331 - loss: 2.5232 - learning_rate: 0.0010\nEpoch 65/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4324 - loss: 2.5315\nEpoch 65: loss improved from 2.55428 to 2.55073, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4324 - loss: 2.5315 - learning_rate: 0.0010\nEpoch 66/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4329 - loss: 2.5364\nEpoch 66: loss improved from 2.55073 to 2.54817, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4329 - loss: 2.5364 - learning_rate: 0.0010\nEpoch 67/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4351 - loss: 2.5186\nEpoch 67: loss improved from 2.54817 to 2.54205, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4351 - loss: 2.5186 - learning_rate: 0.0010\nEpoch 68/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4345 - loss: 2.5234\nEpoch 68: loss did not improve from 2.54205\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4345 - loss: 2.5234 - learning_rate: 0.0010\nEpoch 69/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4321 - loss: 2.5256\nEpoch 69: loss improved from 2.54205 to 2.53811, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4321 - loss: 2.5256 - learning_rate: 0.0010\nEpoch 70/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4333 - loss: 2.5352\nEpoch 70: loss improved from 2.53811 to 2.53805, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4333 - loss: 2.5352 - learning_rate: 0.0010\nEpoch 71/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4341 - loss: 2.5186\nEpoch 71: loss improved from 2.53805 to 2.53408, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4341 - loss: 2.5187 - learning_rate: 0.0010\nEpoch 72/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4316 - loss: 2.5273\nEpoch 72: loss did not improve from 2.53408\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4316 - loss: 2.5274 - learning_rate: 0.0010\nEpoch 73/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4375 - loss: 2.5059\nEpoch 73: loss improved from 2.53408 to 2.52441, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4375 - loss: 2.5059 - learning_rate: 0.0010\nEpoch 74/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4360 - loss: 2.5095\nEpoch 74: loss did not improve from 2.52441\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4360 - loss: 2.5095 - learning_rate: 0.0010\nEpoch 75/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4355 - loss: 2.5075\nEpoch 75: loss did not improve from 2.52441\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 16ms/step - accuracy: 0.4355 - loss: 2.5076 - learning_rate: 0.0010\nEpoch 76/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4359 - loss: 2.5067\nEpoch 76: loss improved from 2.52441 to 2.52257, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4359 - loss: 2.5067 - learning_rate: 0.0010\nEpoch 77/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4370 - loss: 2.4991\nEpoch 77: loss improved from 2.52257 to 2.51465, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4370 - loss: 2.4991 - learning_rate: 0.0010\nEpoch 78/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4364 - loss: 2.4980\nEpoch 78: loss improved from 2.51465 to 2.51298, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4364 - loss: 2.4980 - learning_rate: 0.0010\nEpoch 79/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4391 - loss: 2.4895\nEpoch 79: loss did not improve from 2.51298\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4391 - loss: 2.4895 - learning_rate: 0.0010\nEpoch 80/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4366 - loss: 2.4986\nEpoch 80: loss improved from 2.51298 to 2.50541, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4366 - loss: 2.4986 - learning_rate: 0.0010\nEpoch 81/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4374 - loss: 2.4954\nEpoch 81: loss did not improve from 2.50541\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4374 - loss: 2.4954 - learning_rate: 0.0010\nEpoch 82/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4385 - loss: 2.4866\nEpoch 82: loss improved from 2.50541 to 2.50399, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4385 - loss: 2.4866 - learning_rate: 0.0010\nEpoch 83/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4375 - loss: 2.4914\nEpoch 83: loss improved from 2.50399 to 2.50293, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4375 - loss: 2.4914 - learning_rate: 0.0010\nEpoch 84/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4372 - loss: 2.4930\nEpoch 84: loss improved from 2.50293 to 2.49836, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4372 - loss: 2.4930 - learning_rate: 0.0010\nEpoch 85/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4401 - loss: 2.4899\nEpoch 85: loss did not improve from 2.49836\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4401 - loss: 2.4900 - learning_rate: 0.0010\nEpoch 86/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4398 - loss: 2.4825\nEpoch 86: loss did not improve from 2.49836\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4398 - loss: 2.4825 - learning_rate: 0.0010\nEpoch 87/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4394 - loss: 2.4737\nEpoch 87: loss improved from 2.49836 to 2.49566, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 17ms/step - accuracy: 0.4394 - loss: 2.4737 - learning_rate: 0.0010\nEpoch 88/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4396 - loss: 2.4685\nEpoch 88: loss improved from 2.49566 to 2.49313, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4396 - loss: 2.4685 - learning_rate: 0.0010\nEpoch 89/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4612 - loss: 2.3183\nEpoch 122: loss improved from 2.33064 to 2.32674, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4612 - loss: 2.3183 - learning_rate: 5.0000e-04\nEpoch 123/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4597 - loss: 2.3240\nEpoch 123: loss did not improve from 2.32674\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4597 - loss: 2.3240 - learning_rate: 5.0000e-04\nEpoch 124/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4587 - loss: 2.3255\nEpoch 124: loss did not improve from 2.32674\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4587 - loss: 2.3255 - learning_rate: 5.0000e-04\nEpoch 125/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4617 - loss: 2.3104\nEpoch 125: loss improved from 2.32674 to 2.32156, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4617 - loss: 2.3104 - learning_rate: 5.0000e-04\nEpoch 126/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4634 - loss: 2.3107\nEpoch 129: loss improved from 2.32108 to 2.31653, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4634 - loss: 2.3107 - learning_rate: 5.0000e-04\nEpoch 130/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4615 - loss: 2.3139\nEpoch 130: loss improved from 2.31653 to 2.31544, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 16ms/step - accuracy: 0.4615 - loss: 2.3139 - learning_rate: 5.0000e-04\nEpoch 131/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4627 - loss: 2.3062\nEpoch 131: loss did not improve from 2.31544\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4627 - loss: 2.3062 - learning_rate: 5.0000e-04\nEpoch 132/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4618 - loss: 2.3001\nEpoch 132: loss improved from 2.31544 to 2.31080, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4618 - loss: 2.3001 - learning_rate: 5.0000e-04\nEpoch 133/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4622 - loss: 2.3079\nEpoch 133: loss improved from 2.31080 to 2.30939, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4622 - loss: 2.3079 - learning_rate: 5.0000e-04\nEpoch 134/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4629 - loss: 2.2981\nEpoch 136: loss did not improve from 2.30890\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4629 - loss: 2.2982 - learning_rate: 5.0000e-04\nEpoch 137/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4625 - loss: 2.3011\nEpoch 137: loss improved from 2.30890 to 2.30790, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4625 - loss: 2.3011 - learning_rate: 5.0000e-04\nEpoch 138/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4632 - loss: 2.3015\nEpoch 138: loss improved from 2.30790 to 2.30535, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4632 - loss: 2.3015 - learning_rate: 5.0000e-04\nEpoch 139/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4606 - loss: 2.3019\nEpoch 139: loss did not improve from 2.30535\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4606 - loss: 2.3019 - learning_rate: 5.0000e-04\nEpoch 140/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4636 - loss: 2.2953\nEpoch 140: loss improved from 2.30535 to 2.29840, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4636 - loss: 2.2953 - learning_rate: 5.0000e-04\nEpoch 141/150\n\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4637 - loss: 2.2962\nEpoch 141: loss did not improve from 2.29840\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4637 - loss: 2.2962 - learning_rate: 5.0000e-04\nEpoch 142/150\n\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4655 - loss: 2.2794\nEpoch 144: loss did not improve from 2.29590\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4655 - loss: 2.2795 - learning_rate: 5.0000e-04\nEpoch 145/150\n\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4655 - loss: 2.2893\nEpoch 145: loss improved from 2.29590 to 2.29085, saving model to best_story_model.keras\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 17ms/step - accuracy: 0.4655 - loss: 2.2893 - learning_rate: 5.0000e-04\nEpoch 146/150\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4665 - loss: 2.2788\nEpoch 146: loss did not improve from 2.29085\n\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 16ms/step - accuracy: 0.4665 - loss: 2.2788 - learning_rate: 5.0000e-04\nEpoch 147/150\n\u001b[1m2214/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 16ms/step - accuracy: 0.4649 - loss: 2.2886","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"**Saving the tokenizer and the basic model parameters**","metadata":{}},{"cell_type":"code","source":"with open('tokenizer.pickle', 'wb') as handle:\n    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\n\nmodel_params = {\n    'max_sequence_len': max_sequence_len,\n    'total_words': total_words,\n    'vocab_size': MAX_VOCAB_SIZE\n}\n\nwith open('model_params.pickle', 'wb') as handle:\n    pickle.dump(model_params, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\nprint(\"Model and tokenizer saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T02:17:32.880963Z","iopub.execute_input":"2025-08-12T02:17:32.881816Z","iopub.status.idle":"2025-08-12T02:17:32.892426Z","shell.execute_reply.started":"2025-08-12T02:17:32.881786Z","shell.execute_reply":"2025-08-12T02:17:32.891823Z"}},"outputs":[{"name":"stdout","text":"Model and tokenizer saved!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"**Creating story gen function**","metadata":{}},{"cell_type":"code","source":"def generate_text(seed_text, next_words=50, model=model, tokenizer=tokenizer, max_sequence_len=max_sequence_len):\n    \n    for _ in range(next_words):\n        # Clean and tokenize the seed text\n        token_list = tokenizer.texts_to_sequences([clean_data(seed_text)])[0]\n        token_list = token_list[-(max_sequence_len-1):]  # Keep only last max_sequence_len-1 tokens\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        \n        # Predict next word\n        predicted = model.predict(token_list, verbose=0)\n        predicted_id = np.argmax(predicted)\n        \n        # Find the word corresponding to the predicted ID\n        output_word = \"\"\n        for word, index in tokenizer.word_index.items():\n            if index == predicted_id:\n                output_word = word\n                break\n        \n        if output_word:\n            seed_text += \" \" + output_word\n        else:\n            break\n    \n    return seed_text\n\n# Example usage (uncomment after training):\nsample_text = \"Under the glowing blue moon, the tiny dragon peeked out from the enchanted forest and saw\"\ngenerated_story = generate_text(sample_text, next_words=100)\nprint(\"Generated story:\")\nprint(generated_story)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T02:17:35.820634Z","iopub.execute_input":"2025-08-12T02:17:35.820914Z","iopub.status.idle":"2025-08-12T02:17:44.264905Z","shell.execute_reply.started":"2025-08-12T02:17:35.820894Z","shell.execute_reply":"2025-08-12T02:17:44.264200Z"}},"outputs":[{"name":"stdout","text":"Generated story:\nUnder the glowing blue moon, the tiny dragon peeked out from the enchanted forest and saw a little boy named jack he was very excited and asked his mom if he could go on a big tree but the little girl said yes i dont want to play asked me me me me me me me me me me me me me me pointing at the ground thats so much the little girl nodded and nodded the little girl was so excited she asked her mom if she could go to the park and get a big smile she said yes but the little girl was so happy she asked her mom if she could go\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}