{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a201886-7056-4892-bb08-c4ca267702c2",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d82e13d4-e009-42ef-8923-e08dcd195f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import spacy\n",
    "import logging\n",
    "from spacy.training import Example,offsets_to_biluo_tags\n",
    "from spacy.tokens import Doc, Span\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support,  accuracy_score\n",
    "from spacy.scorer import Scorer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e221c9fb-0471-45dd-b6a1-96aa71654928",
   "metadata": {},
   "source": [
    "## Loading json files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "673548bb-55db-4be3-93bf-a93afadcb9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = 'C:/Users/madhu/OneDrive/Desktop/ACM/Named_Entity_Recognition/NER/traindata.json' \n",
    "test_file_path = 'C:/Users/madhu/OneDrive/Desktop/ACM/Named_Entity_Recognition/NER/testdata.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d85a553-428d-4d33-958a-9aa843531d93",
   "metadata": {},
   "source": [
    "### Loading train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46acdcc4-1eaa-45bb-9b4a-ef07791a271c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'Govardhana K\\nSenior Software Engineer\\n\\nBengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/\\nb2de315d95905b68\\n\\nTotal IT experience 5 Years 6 Months\\nCloud Lending Solutions INC 4 Month • Salesforce Developer\\nOracle 5 Years 2 Month • Core Java Developer\\nLanguages Core Java, Go Lang\\nOracle PL-SQL programming,\\nSales Force Developer with APEX.\\n\\nDesignations & Promotions\\n\\nWilling to relocate: Anywhere\\n\\nWORK EXPERIENCE\\n\\nSenior Software Engineer\\n\\nCloud Lending Solutions -  Bangalore, Karnataka -\\n\\nJanuary 2018 to Present\\n\\nPresent\\n\\nSenior Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nNovember 2016 to December 2017\\n\\nStaff Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nJanuary 2014 to October 2016\\n\\nAssociate Consultant\\n\\nOracle -  Bangalore, Karnataka -\\n\\nNovember 2012 to December 2013\\n\\nEDUCATION\\n\\nB.E in Computer Science Engineering\\n\\nAdithya Institute of Technology -  Tamil Nadu\\n\\nSeptember 2008 to June 2012\\n\\nhttps://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN\\nhttps://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN\\n\\n\\nSKILLS\\n\\nAPEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years),\\nAlgorithms (3 years)\\n\\nLINKS\\n\\nhttps://www.linkedin.com/in/govardhana-k-61024944/\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Proficiency:\\n\\nLanguages: Core Java, Go Lang, Data Structures & Algorithms, Oracle\\nPL-SQL programming, Sales Force with APEX.\\nTools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer,\\nPL/SQL Developer, WinSCP, Putty\\nWeb Technologies: JavaScript, XML, HTML, Webservice\\n\\nOperating Systems: Linux, Windows\\nVersion control system SVN & Git-Hub\\nDatabases: Oracle\\nMiddleware: Web logic, OC4J\\nProduct FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x\\n\\nhttps://www.linkedin.com/in/govardhana-k-61024944/', 'annotation': [{'label': ['Companies worked at'], 'points': [{'start': 1749, 'end': 1754, 'text': 'Oracle'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1696, 'end': 1701, 'text': 'Oracle'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1417, 'end': 1422, 'text': 'Oracle'}]}, {'label': ['Skills'], 'points': [{'start': 1356, 'end': 1792, 'text': 'Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle\\nPL-SQL programming, Sales Force with APEX.\\nTools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer,\\nPL/SQL Developer, WinSCP, Putty\\nWeb Technologies: JavaScript, XML, HTML, Webservice\\n\\nOperating Systems: Linux, Windows\\nVersion control system SVN & Git-Hub\\nDatabases: Oracle\\nMiddleware: Web logic, OC4J\\nProduct FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x'}]}, {'label': ['Companies worked at'], 'points': [{'start': 1209, 'end': 1214, 'text': 'Oracle'}]}, {'label': ['Skills'], 'points': [{'start': 1136, 'end': 1247, 'text': 'APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years),\\nAlgorithms (3 years)\\n'}]}, {'label': ['Graduation Year'], 'points': [{'start': 928, 'end': 931, 'text': '2012'}]}, {'label': ['College Name'], 'points': [{'start': 858, 'end': 888, 'text': 'Adithya Institute of Technology'}]}, {'label': ['Degree'], 'points': [{'start': 821, 'end': 855, 'text': 'B.E in Computer Science Engineering'}]}, {'label': ['Graduation Year'], 'points': [{'start': 787, 'end': 790, 'text': '2012'}]}, {'label': ['Companies worked at'], 'points': [{'start': 744, 'end': 749, 'text': 'Oracle'}]}, {'label': ['Designation'], 'points': [{'start': 722, 'end': 741, 'text': 'Associate Consultant'}]}, {'label': ['Companies worked at'], 'points': [{'start': 658, 'end': 663, 'text': 'Oracle'}]}, {'label': ['Designation'], 'points': [{'start': 640, 'end': 655, 'text': 'Staff Consultant'}]}, {'label': ['Companies worked at'], 'points': [{'start': 574, 'end': 579, 'text': 'Oracle'}]}, {'label': ['Designation'], 'points': [{'start': 555, 'end': 572, 'text': 'Senior Consultant\\n'}]}, {'label': ['Companies worked at'], 'points': [{'start': 470, 'end': 492, 'text': 'Cloud Lending Solutions'}]}, {'label': ['Designation'], 'points': [{'start': 444, 'end': 468, 'text': 'Senior Software Engineer\\n'}]}, {'label': ['Companies worked at'], 'points': [{'start': 308, 'end': 313, 'text': 'Oracle'}]}, {'label': ['Companies worked at'], 'points': [{'start': 234, 'end': 239, 'text': 'Oracle'}]}, {'label': ['Companies worked at'], 'points': [{'start': 175, 'end': 197, 'text': 'Cloud Lending Solutions'}]}, {'label': ['Email Address'], 'points': [{'start': 93, 'end': 136, 'text': 'indeed.com/r/Govardhana-K/\\nb2de315d95905b68\\n'}]}, {'label': ['Location'], 'points': [{'start': 39, 'end': 47, 'text': 'Bengaluru'}]}, {'label': ['Designation'], 'points': [{'start': 13, 'end': 37, 'text': 'Senior Software Engineer\\n'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Govardhana K'}]}]}\n"
     ]
    }
   ],
   "source": [
    "train_data=[]\n",
    "with open(train_file_path , 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        resume = json.loads(line)\n",
    "        train_data.append(resume)\n",
    "\n",
    "if train_data:\n",
    "    print(train_data[0])      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488c14d-c0d8-4e04-b417-cd98f24336c4",
   "metadata": {},
   "source": [
    "### Loading test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0a473aa-8368-40d2-ad39-229a05f17cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "with open(test_file_path , 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        resume = json.loads(line)\n",
    "        test_data.append(resume)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa26ec0-f272-41bf-91b3-e28c9d14a7e5",
   "metadata": {},
   "source": [
    "## Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f26d4d-20af-4a38-b1b5-34ab7c7a2780",
   "metadata": {},
   "source": [
    "### Removing white spaces and new line characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "770c4c12-5711-4ecf-a42f-15de86b85ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "for entry in train_data:\n",
    "    entry['content'] = clean_text(entry['content'])\n",
    "\n",
    "for entry in test_data:\n",
    "    entry['content'] = clean_text(entry['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fc010-4ab6-4caf-b50d-78bbd32a89d7",
   "metadata": {},
   "source": [
    "### Removing overlapping entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd56d1c8-360e-4410-8400-523443d259a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_overlapping_entities(annotations):\n",
    "    entities = sorted(annotations['entities'], key=lambda x: (x[0], x[1]))\n",
    "    filtered_entities = []\n",
    "    prev_start, prev_end = -1, -1\n",
    "\n",
    "    for start, end, label in entities:\n",
    "        if start >= prev_end:\n",
    "            filtered_entities.append((start, end, label))\n",
    "            prev_start, prev_end = start, end\n",
    "        else:\n",
    "            if end > prev_end:\n",
    "                if filtered_entities:\n",
    "                    filtered_entities.pop()  # Remove the last entity\n",
    "                filtered_entities.append((start, end, label))\n",
    "                prev_start, prev_end = start, end\n",
    "\n",
    "    annotations['entities'] = filtered_entities\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87524b85-60b7-445e-a6ca-7dc53bd14d25",
   "metadata": {},
   "source": [
    "### Function to filter misaligned entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "804be196-693f-473f-a8a3-789981d3bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_misaligned_entities(nlp, text, entities):\n",
    "    biluo_tags = offsets_to_biluo_tags(nlp.make_doc(text), entities)\n",
    "    return [entity for entity, tag in zip(entities, biluo_tags) if tag != 'O']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d8531-b822-4b90-8e86-3b5d9af1e661",
   "metadata": {},
   "source": [
    "## Function to convert data to spaCy format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "31f6630a-861b-442f-870c-5a03c3450cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_spacy(data):\n",
    "    processed_data = []\n",
    "\n",
    "    for data in data:\n",
    "        text = data['content']\n",
    "        entities = []\n",
    "        for annotation in data['annotation']:\n",
    "            # Only a single point in text annotation.\n",
    "            point = annotation['points'][0]\n",
    "            start = point['start']\n",
    "            end = point['end'] + 1\n",
    "            entity_text = text[start:end].strip()\n",
    "\n",
    "            # Correct start and end positions based on stripped text.\n",
    "            start = text.index(entity_text)\n",
    "            end = start + len(entity_text)\n",
    "\n",
    "            labels = annotation['label']\n",
    "            # Handle both list of labels or a single label.\n",
    "            if not isinstance(labels, list):\n",
    "                labels = [labels]\n",
    "\n",
    "            for label in labels:\n",
    "                # Dataturks indices are both inclusive [start, end] but Spacy is not [start, end)\n",
    "                entities.append((point['start'], point['end'] + 1, label))\n",
    "\n",
    "        annotations = {\"entities\": entities}\n",
    "        annotations = remove_overlapping_entities(annotations)  # Clean overlapping entities\n",
    "         # Filter out misaligned entities\n",
    "        entities = filter_misaligned_entities(nlp, text, annotations['entities'])\n",
    "        processed_data.append((text, annotations))\n",
    "\n",
    "    return processed_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb91cdc-444d-485b-a6d2-ca42f35a5a46",
   "metadata": {},
   "source": [
    "### Converting the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9f70bde7-0ed4-46bf-af8d-8fcb7b079cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = convert_data_to_spacy(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "daaa8005-fc12-4008-9869-547fe7607698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Govardhana K Senior Software Engineer Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68 Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX. Designations & Promotions Willing to relocate: Anywhere WORK EXPERIENCE Senior Software Engineer Cloud Lending Solutions - Bangalore, Karnataka - January 2018 to Present Present Senior Consultant Oracle - Bangalore, Karnataka - November 2016 to December 2017 Staff Consultant Oracle - Bangalore, Karnataka - January 2014 to October 2016 Associate Consultant Oracle - Bangalore, Karnataka - November 2012 to December 2013 EDUCATION B.E in Computer Science Engineering Adithya Institute of Technology - Tamil Nadu September 2008 to June 2012 https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN SKILLS APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years) LINKS https://www.linkedin.com/in/govardhana-k-61024944/ ADDITIONAL INFORMATION Technical Proficiency: Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x https://www.linkedin.com/in/govardhana-k-61024944/', {'entities': [(0, 12, 'Name'), (13, 38, 'Designation'), (39, 48, 'Location'), (93, 137, 'Email Address'), (175, 198, 'Companies worked at'), (234, 240, 'Companies worked at'), (308, 314, 'Companies worked at'), (444, 469, 'Designation'), (470, 493, 'Companies worked at'), (555, 573, 'Designation'), (574, 580, 'Companies worked at'), (640, 656, 'Designation'), (658, 664, 'Companies worked at'), (722, 742, 'Designation'), (744, 750, 'Companies worked at'), (787, 791, 'Graduation Year'), (821, 856, 'Degree'), (858, 889, 'College Name'), (928, 932, 'Graduation Year'), (1136, 1248, 'Skills'), (1356, 1793, 'Skills')]})\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7e4826-aaf2-42cf-867b-f74722f58a08",
   "metadata": {},
   "source": [
    "## Load blank english model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "784eb8b5-7204-4da5-9ce8-7512181b9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " nlp = spacy.blank('en')  # Create blank Language class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d3bd6-2e8d-4f64-b2d4-f7ec9a2a137d",
   "metadata": {},
   "source": [
    "### Adding the NER pipeline component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2ce90830-898d-4226-b12a-02afa53ee456",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe('ner', last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4dcd1b-5218-4218-8cd4-a0990976272a",
   "metadata": {},
   "source": [
    "### Adding labels to the NER component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3aa0349-763a-463c-9edf-293194e24bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef31a557-9427-49c8-adcc-6988c322864d",
   "metadata": {},
   "source": [
    "### Disabling other pipeline components to only train NER\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2a5dbc54-8c9b-4773-a347-a69a9ac0e332",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # Only train NER\n",
    "    optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fe039-3fc3-4fb1-94c7-69c502162a52",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "46c9968f-30e5-4b9d-a6fe-bad48fd66f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_spacy(train_data, iterations=10):\n",
    "    for itn in range(iterations):\n",
    "        print(f\"Starting iteration {itn}\")\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        for text, annotations in train_data:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update(\n",
    "                [example],  # Batch of Example objects\n",
    "                drop=0.2,  # Dropout - make it harder to memorize data\n",
    "                sgd=optimizer,  # Callable to update weights\n",
    "                losses=losses\n",
    "            )\n",
    "        print(losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "abcce2ba-a89c-416b-8536-3a9f7707b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0\n",
      "{'ner': 4314.65722655211}\n",
      "Starting iteration 1\n",
      "{'ner': 601.3107491989562}\n",
      "Starting iteration 2\n",
      "{'ner': 925.4968483394929}\n",
      "Starting iteration 3\n",
      "{'ner': 414.3662813244367}\n",
      "Starting iteration 4\n",
      "{'ner': 606.333228907427}\n",
      "Starting iteration 5\n",
      "{'ner': 699.9589178571306}\n",
      "Starting iteration 6\n",
      "{'ner': 786.1347077396551}\n",
      "Starting iteration 7\n",
      "{'ner': 597.2934646112649}\n",
      "Starting iteration 8\n",
      "{'ner': 382.6191091736131}\n",
      "Starting iteration 9\n",
      "{'ner': 558.6145360851781}\n"
     ]
    }
   ],
   "source": [
    "nlp_model = train_spacy(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b920e1-2c10-4f65-8121-abf5e83ce7fd",
   "metadata": {},
   "source": [
    "## Predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1efc7ca1-565a-41c8-901d-4644c4824439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities in test text 0:\n",
      " - Abhishek Jha: Name\n",
      " - Application Development Associate - Accenture: Designation\n",
      " - indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a: Email Address\n",
      "\n",
      "\n",
      "Entities in test text 1:\n",
      " - Afreen Jamadar: Name\n",
      " - Active member: Designation\n",
      "\n",
      "\n",
      "Entities in test text 2:\n",
      " - Akhil Yadav: Name\n",
      " - Polemaina: Location\n",
      "\n",
      "\n",
      "Entities in test text 3:\n",
      " - Alok Khandai: Name\n",
      " - Operational Analyst (SQL DBA): Designation\n",
      " - Bengaluru: Location\n",
      "\n",
      "\n",
      "Entities in test text 4:\n",
      " - Ananya Chavan: Name\n",
      "\n",
      "\n",
      "Entities in test text 5:\n",
      " - Anvitha Rao: Name\n",
      " - Automation developer: Designation\n",
      " - of Technology - Bengaluru, Karnataka September 2012: College Name\n",
      "\n",
      "\n",
      "Entities in test text 6:\n",
      " - arjun ks: Name\n",
      "\n",
      "\n",
      "Entities in test text 7:\n",
      " - Arun Elumalai: Name\n",
      "\n",
      "\n",
      "Entities in test text 8:\n",
      " - Ashalata Bisoyi: Name\n",
      "\n",
      "\n",
      "Entities in test text 9:\n",
      " - Ashok Kunam: Name\n",
      " - Team Lead: Designation\n",
      " - Microsoft: Companies worked at\n",
      "\n",
      "\n",
      "Entities in test text 10:\n",
      " - Asish Ratha: Name\n",
      " - Subject matter Expert: Designation\n",
      "\n",
      "\n",
      "Entities in test text 11:\n",
      " - Avin Sharma: Name\n",
      " - Senior Associate Consultant: Designation\n",
      " - Infosys Limited: Companies worked at\n",
      "\n",
      "\n",
      "Entities in test text 12:\n",
      " - Ayesha B: Name\n",
      " - Team member: Designation\n",
      " - Oracle: Companies worked at\n",
      "\n",
      "\n",
      "Entities in test text 13:\n",
      " - Ayushi Srivastava: Name\n",
      " - Senior Analyst: Designation\n",
      " - Cisco: Companies worked at\n",
      " - New Delhi: Location\n",
      "\n",
      "\n",
      "Entities in test text 14:\n",
      " - Bhawana Daf: Name\n",
      "\n",
      "\n",
      "Entities in test text 15:\n",
      " - Darshan G.: Name\n",
      " - Financial Analyst: Designation\n",
      " - Oracle: Companies worked at\n",
      " - Bengaluru: Location\n",
      "\n",
      "\n",
      "Entities in test text 16:\n",
      " - Dhanushkodi Raj: Name\n",
      " - Infosys Limited: Companies worked at\n",
      "\n",
      "\n",
      "Entities in test text 17:\n",
      " - Dinesh Reddy: Name\n",
      " - Deployed chef for configuration management infrastructure: Designation\n",
      "\n",
      "\n",
      "Entities in test text 18:\n",
      " - Dipesh Gulati: Name\n",
      "\n",
      "\n",
      "Entities in test text 19:\n",
      " - Dushyant Bhatt: Name\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test_data):\n",
    "    text = data['content']\n",
    "    doc = nlp_model(text)\n",
    "    print(f\"Entities in test text {i}:\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\" - {ent.text}: {ent.label_}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d318e4c-e70a-40cb-a5ca-30f09bddd892",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2eaa632d-b258-4362-b88e-78302a472306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:/Users/madhu/OneDrive/Desktop/ACM/Named_Entity_Recognition/NER/ner_model\n"
     ]
    }
   ],
   "source": [
    "output_path = 'C:/Users/madhu/OneDrive/Desktop/ACM/Named_Entity_Recognition/NER/ner_model'\n",
    "nlp.to_disk(output_path)\n",
    "print(f\"Model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd442d-f586-4004-8530-cd47ae018029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
